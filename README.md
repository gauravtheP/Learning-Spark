# Learning-Spark
Here, I have implemented spark codes for basic understanding of spark and particularly Resilient Distributed Datasets(RDD).
If you want to use this repository for learning purpose then simply download this repository then run the file in the following order:
1. Basics-of-RDD
2. Working-With-DF
3. File-Recommender-System
4. K-Means-Clustering-Spark
5. DT-In-Spark
6. Search-In-Spark
